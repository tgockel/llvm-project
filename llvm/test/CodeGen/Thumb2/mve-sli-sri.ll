; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py
; RUN: llc -mtriple=thumbv8.1m.main-none-none-eabihf -mattr=+mve -verify-machineinstrs %s -o - | FileCheck %s

define <8 x i8> @testLeftGood8x8(<8 x i8> %src1, <8 x i8> %src2) {
; CHECK-LABEL: testLeftGood8x8:
; CHECK:       @ %bb.0:
; CHECK-NEXT:    vsli.16 q0, q1, #3
; CHECK-NEXT:    bx lr
  %and.i = and <8 x i8> %src1, <i8 7, i8 7, i8 7, i8 7, i8 7, i8 7, i8 7, i8 7>
  %vshl_n = shl <8 x i8> %src2, <i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3>
  %result = or <8 x i8> %and.i, %vshl_n
  ret <8 x i8> %result
}

define <8 x i8> @testLeftBad8x8(<8 x i8> %src1, <8 x i8> %src2) {
; CHECK-LABEL: testLeftBad8x8:
; CHECK:       @ %bb.0:
; CHECK-NEXT:    vmov.i16 q2, #0xa5
; CHECK-NEXT:    vshl.i16 q1, q1, #1
; CHECK-NEXT:    vand q0, q0, q2
; CHECK-NEXT:    vorr q0, q0, q1
; CHECK-NEXT:    bx lr
  %and.i = and <8 x i8> %src1, <i8 165, i8 165, i8 165, i8 165, i8 165, i8 165, i8 165, i8 165>
  %vshl_n = shl <8 x i8> %src2, <i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1>
  %result = or <8 x i8> %and.i, %vshl_n
  ret <8 x i8> %result
}

define <8 x i8> @testRightGood8x8(<8 x i8> %src1, <8 x i8> %src2) {
; CHECK-LABEL: testRightGood8x8:
; CHECK:       @ %bb.0:
; CHECK-NEXT:    vmovlb.u8 q1, q1
; CHECK-NEXT:    vmov.i16 q2, #0xe0
; CHECK-NEXT:    vand q0, q0, q2
; CHECK-NEXT:    vshr.u16 q1, q1, #3
; CHECK-NEXT:    vorr q0, q0, q1
; CHECK-NEXT:    bx lr
  %and.i = and <8 x i8> %src1, <i8 224, i8 224, i8 224, i8 224, i8 224, i8 224, i8 224, i8 224>
  %vshl_n = lshr <8 x i8> %src2, <i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3>
  %result = or <8 x i8> %and.i, %vshl_n
  ret <8 x i8> %result
}

define <8 x i8> @testRightBad8x8(<8 x i8> %src1, <8 x i8> %src2) {
; CHECK-LABEL: testRightBad8x8:
; CHECK:       @ %bb.0:
; CHECK-NEXT:    vmovlb.u8 q1, q1
; CHECK-NEXT:    vmov.i16 q2, #0xa5
; CHECK-NEXT:    vand q0, q0, q2
; CHECK-NEXT:    vshr.u16 q1, q1, #1
; CHECK-NEXT:    vorr q0, q0, q1
; CHECK-NEXT:    bx lr
  %and.i = and <8 x i8> %src1, <i8 165, i8 165, i8 165, i8 165, i8 165, i8 165, i8 165, i8 165>
  %vshl_n = lshr <8 x i8> %src2, <i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1>
  %result = or <8 x i8> %and.i, %vshl_n
  ret <8 x i8> %result
}

define <16 x i8> @testLeftGood16x8(<16 x i8> %src1, <16 x i8> %src2) {
; CHECK-LABEL: testLeftGood16x8:
; CHECK:       @ %bb.0:
; CHECK-NEXT:    vsli.8 q0, q1, #3
; CHECK-NEXT:    bx lr
  %and.i = and <16 x i8> %src1, <i8 7, i8 7, i8 7, i8 7, i8 7, i8 7, i8 7, i8 7, i8 7, i8 7, i8 7, i8 7, i8 7, i8 7, i8 7, i8 7>
  %vshl_n = shl <16 x i8> %src2, <i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3>
  %result = or <16 x i8> %and.i, %vshl_n
  ret <16 x i8> %result
}

define <16 x i8> @testLeftBad16x8(<16 x i8> %src1, <16 x i8> %src2) {
; CHECK-LABEL: testLeftBad16x8:
; CHECK:       @ %bb.0:
; CHECK-NEXT:    vmov.i8 q2, #0xa5
; CHECK-NEXT:    vshl.i8 q1, q1, #1
; CHECK-NEXT:    vand q0, q0, q2
; CHECK-NEXT:    vorr q0, q0, q1
; CHECK-NEXT:    bx lr
  %and.i = and <16 x i8> %src1, <i8 165, i8 165, i8 165, i8 165, i8 165, i8 165, i8 165, i8 165, i8 165, i8 165, i8 165, i8 165, i8 165, i8 165, i8 165, i8 165>
  %vshl_n = shl <16 x i8> %src2, <i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1>
  %result = or <16 x i8> %and.i, %vshl_n
  ret <16 x i8> %result
}

define <16 x i8> @testRightGood16x8(<16 x i8> %src1, <16 x i8> %src2) {
; CHECK-LABEL: testRightGood16x8:
; CHECK:       @ %bb.0:
; CHECK-NEXT:    vsri.8 q0, q1, #3
; CHECK-NEXT:    bx lr
  %and.i = and <16 x i8> %src1, <i8 224, i8 224, i8 224, i8 224, i8 224, i8 224, i8 224, i8 224, i8 224, i8 224, i8 224, i8 224, i8 224, i8 224, i8 224, i8 224>
  %vshl_n = lshr <16 x i8> %src2, <i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3>
  %result = or <16 x i8> %and.i, %vshl_n
  ret <16 x i8> %result
}

define <16 x i8> @testRightBad16x8(<16 x i8> %src1, <16 x i8> %src2) {
; CHECK-LABEL: testRightBad16x8:
; CHECK:       @ %bb.0:
; CHECK-NEXT:    vmov.i8 q2, #0xa5
; CHECK-NEXT:    vshr.u8 q1, q1, #1
; CHECK-NEXT:    vand q0, q0, q2
; CHECK-NEXT:    vorr q0, q0, q1
; CHECK-NEXT:    bx lr
  %and.i = and <16 x i8> %src1, <i8 165, i8 165, i8 165, i8 165, i8 165, i8 165, i8 165, i8 165, i8 165, i8 165, i8 165, i8 165, i8 165, i8 165, i8 165, i8 165>
  %vshl_n = lshr <16 x i8> %src2, <i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1, i8 1>
  %result = or <16 x i8> %and.i, %vshl_n
  ret <16 x i8> %result
}

define <4 x i16> @testLeftGood4x16(<4 x i16> %src1, <4 x i16> %src2) {
; CHECK-LABEL: testLeftGood4x16:
; CHECK:       @ %bb.0:
; CHECK-NEXT:    vsli.32 q0, q1, #14
; CHECK-NEXT:    bx lr
  %and.i = and <4 x i16> %src1, <i16 16383, i16 16383, i16 16383, i16 16383>
  %vshl_n = shl <4 x i16> %src2, <i16 14, i16 14, i16 14, i16 14>
  %result = or <4 x i16> %and.i, %vshl_n
  ret <4 x i16> %result
}

define <4 x i16> @testLeftBad4x16(<4 x i16> %src1, <4 x i16> %src2) {
; CHECK-LABEL: testLeftBad4x16:
; CHECK:       @ %bb.0:
; CHECK-NEXT:    movw r0, #16500
; CHECK-NEXT:    vshl.i32 q1, q1, #14
; CHECK-NEXT:    vdup.32 q2, r0
; CHECK-NEXT:    vand q0, q0, q2
; CHECK-NEXT:    vorr q0, q0, q1
; CHECK-NEXT:    bx lr
  %and.i = and <4 x i16> %src1, <i16 16500, i16 16500, i16 16500, i16 16500>
  %vshl_n = shl <4 x i16> %src2, <i16 14, i16 14, i16 14, i16 14>
  %result = or <4 x i16> %and.i, %vshl_n
  ret <4 x i16> %result
}

define <4 x i16> @testRightGood4x16(<4 x i16> %src1, <4 x i16> %src2) {
; CHECK-LABEL: testRightGood4x16:
; CHECK:       @ %bb.0:
; CHECK-NEXT:    movw r0, #65532
; CHECK-NEXT:    vmovlb.u16 q1, q1
; CHECK-NEXT:    vdup.32 q2, r0
; CHECK-NEXT:    vshr.u32 q1, q1, #14
; CHECK-NEXT:    vand q0, q0, q2
; CHECK-NEXT:    vorr q0, q0, q1
; CHECK-NEXT:    bx lr
  %and.i = and <4 x i16> %src1, <i16 65532, i16 65532, i16 65532, i16 65532>
  %vshl_n = lshr <4 x i16> %src2, <i16 14, i16 14, i16 14, i16 14>
  %result = or <4 x i16> %and.i, %vshl_n
  ret <4 x i16> %result
}

define <4 x i16> @testRightBad4x16(<4 x i16> %src1, <4 x i16> %src2) {
; CHECK-LABEL: testRightBad4x16:
; CHECK:       @ %bb.0:
; CHECK-NEXT:    movw r0, #16500
; CHECK-NEXT:    vmovlb.u16 q1, q1
; CHECK-NEXT:    vdup.32 q2, r0
; CHECK-NEXT:    vshr.u32 q1, q1, #14
; CHECK-NEXT:    vand q0, q0, q2
; CHECK-NEXT:    vorr q0, q0, q1
; CHECK-NEXT:    bx lr
  %and.i = and <4 x i16> %src1, <i16 16500, i16 16500, i16 16500, i16 16500>
  %vshl_n = lshr <4 x i16> %src2, <i16 14, i16 14, i16 14, i16 14>
  %result = or <4 x i16> %and.i, %vshl_n
  ret <4 x i16> %result
}

define <8 x i16> @testLeftGood8x16(<8 x i16> %src1, <8 x i16> %src2) {
; CHECK-LABEL: testLeftGood8x16:
; CHECK:       @ %bb.0:
; CHECK-NEXT:    vshl.i16 q1, q1, #14
; CHECK-NEXT:    vbic.i16 q0, #0xc000
; CHECK-NEXT:    vorr q0, q0, q1
; CHECK-NEXT:    bx lr
  %and.i = and <8 x i16> %src1, <i16 16383, i16 16383, i16 16383, i16 16383, i16 16383, i16 16383, i16 16383, i16 16383>
  %vshl_n = shl <8 x i16> %src2, <i16 14, i16 14, i16 14, i16 14, i16 14, i16 14, i16 14, i16 14>
  %result = or <8 x i16> %and.i, %vshl_n
  ret <8 x i16> %result
}

define <8 x i16> @testLeftBad8x16(<8 x i16> %src1, <8 x i16> %src2) {
; CHECK-LABEL: testLeftBad8x16:
; CHECK:       @ %bb.0:
; CHECK-NEXT:    movw r0, #16500
; CHECK-NEXT:    vshl.i16 q1, q1, #14
; CHECK-NEXT:    vdup.16 q2, r0
; CHECK-NEXT:    vand q0, q0, q2
; CHECK-NEXT:    vorr q0, q0, q1
; CHECK-NEXT:    bx lr
  %and.i = and <8 x i16> %src1, <i16 16500, i16 16500, i16 16500, i16 16500, i16 16500, i16 16500, i16 16500, i16 16500>
  %vshl_n = shl <8 x i16> %src2, <i16 14, i16 14, i16 14, i16 14, i16 14, i16 14, i16 14, i16 14>
  %result = or <8 x i16> %and.i, %vshl_n
  ret <8 x i16> %result
}

define <8 x i16> @testRightGood8x16(<8 x i16> %src1, <8 x i16> %src2) {
; CHECK-LABEL: testRightGood8x16:
; CHECK:       @ %bb.0:
; CHECK-NEXT:    vshr.u16 q1, q1, #14
; CHECK-NEXT:    vbic.i16 q0, #0x3
; CHECK-NEXT:    vorr q0, q0, q1
; CHECK-NEXT:    bx lr
  %and.i = and <8 x i16> %src1, <i16 65532, i16 65532, i16 65532, i16 65532, i16 65532, i16 65532, i16 65532, i16 65532>
  %vshl_n = lshr <8 x i16> %src2, <i16 14, i16 14, i16 14, i16 14, i16 14, i16 14, i16 14, i16 14>
  %result = or <8 x i16> %and.i, %vshl_n
  ret <8 x i16> %result
}

define <8 x i16> @testRightBad8x16(<8 x i16> %src1, <8 x i16> %src2) {
; CHECK-LABEL: testRightBad8x16:
; CHECK:       @ %bb.0:
; CHECK-NEXT:    movw r0, #16500
; CHECK-NEXT:    vshr.u16 q1, q1, #14
; CHECK-NEXT:    vdup.16 q2, r0
; CHECK-NEXT:    vand q0, q0, q2
; CHECK-NEXT:    vorr q0, q0, q1
; CHECK-NEXT:    bx lr
  %and.i = and <8 x i16> %src1, <i16 16500, i16 16500, i16 16500, i16 16500, i16 16500, i16 16500, i16 16500, i16 16500>
  %vshl_n = lshr <8 x i16> %src2, <i16 14, i16 14, i16 14, i16 14, i16 14, i16 14, i16 14, i16 14>
  %result = or <8 x i16> %and.i, %vshl_n
  ret <8 x i16> %result
}

define <2 x i32> @testLeftGood2x32(<2 x i32> %src1, <2 x i32> %src2) {
; CHECK-LABEL: testLeftGood2x32:
; CHECK:       @ %bb.0:
; CHECK-NEXT:    adr r0, .LCPI16_0
; CHECK-NEXT:    vmov r2, r3, d2
; CHECK-NEXT:    vldrw.u32 q2, [r0]
; CHECK-NEXT:    vmov r0, r1, d3
; CHECK-NEXT:    lsll r0, r1, #22
; CHECK-NEXT:    lsll r2, r3, #22
; CHECK-NEXT:    vmov q1[2], q1[0], r2, r0
; CHECK-NEXT:    vand q0, q0, q2
; CHECK-NEXT:    vmov q1[3], q1[1], r3, r1
; CHECK-NEXT:    vorr q0, q0, q1
; CHECK-NEXT:    bx lr
; CHECK-NEXT:    .p2align 4
; CHECK-NEXT:  @ %bb.1:
; CHECK-NEXT:  .LCPI16_0:
; CHECK-NEXT:    .long 4194303 @ 0x3fffff
; CHECK-NEXT:    .long 0 @ 0x0
; CHECK-NEXT:    .long 4194303 @ 0x3fffff
; CHECK-NEXT:    .long 0 @ 0x0
  %and.i = and <2 x i32> %src1, <i32 4194303, i32 4194303>
  %vshl_n = shl <2 x i32> %src2, <i32 22, i32 22>
  %result = or <2 x i32> %and.i, %vshl_n
  ret <2 x i32> %result
}

define <2 x i32> @testLeftBad2x32(<2 x i32> %src1, <2 x i32> %src2) {
; CHECK-LABEL: testLeftBad2x32:
; CHECK:       @ %bb.0:
; CHECK-NEXT:    adr r0, .LCPI17_0
; CHECK-NEXT:    vmov r2, r3, d2
; CHECK-NEXT:    vldrw.u32 q2, [r0]
; CHECK-NEXT:    vmov r0, r1, d3
; CHECK-NEXT:    lsll r0, r1, #22
; CHECK-NEXT:    lsll r2, r3, #22
; CHECK-NEXT:    vmov q1[2], q1[0], r2, r0
; CHECK-NEXT:    vand q0, q0, q2
; CHECK-NEXT:    vmov q1[3], q1[1], r3, r1
; CHECK-NEXT:    vorr q0, q0, q1
; CHECK-NEXT:    bx lr
; CHECK-NEXT:    .p2align 4
; CHECK-NEXT:  @ %bb.1:
; CHECK-NEXT:  .LCPI17_0:
; CHECK-NEXT:    .long 4194300 @ 0x3ffffc
; CHECK-NEXT:    .long 0 @ 0x0
; CHECK-NEXT:    .long 4194300 @ 0x3ffffc
; CHECK-NEXT:    .long 0 @ 0x0
  %and.i = and <2 x i32> %src1, <i32 4194300, i32 4194300>
  %vshl_n = shl <2 x i32> %src2, <i32 22, i32 22>
  %result = or <2 x i32> %and.i, %vshl_n
  ret <2 x i32> %result
}

define <2 x i32> @testRightGood2x32(<2 x i32> %src1, <2 x i32> %src2) {
; CHECK-LABEL: testRightGood2x32:
; CHECK:       @ %bb.0:
; CHECK-NEXT:    vmov.i64 q2, #0xffffffff
; CHECK-NEXT:    vand q1, q1, q2
; CHECK-NEXT:    vmov r0, r1, d3
; CHECK-NEXT:    vmov r2, r3, d2
; CHECK-NEXT:    lsrl r0, r1, #22
; CHECK-NEXT:    lsrl r2, r3, #22
; CHECK-NEXT:    vmov q1[2], q1[0], r2, r0
; CHECK-NEXT:    adr r0, .LCPI18_0
; CHECK-NEXT:    vldrw.u32 q2, [r0]
; CHECK-NEXT:    vmov q1[3], q1[1], r3, r1
; CHECK-NEXT:    vand q0, q0, q2
; CHECK-NEXT:    vorr q0, q0, q1
; CHECK-NEXT:    bx lr
; CHECK-NEXT:    .p2align 4
; CHECK-NEXT:  @ %bb.1:
; CHECK-NEXT:  .LCPI18_0:
; CHECK-NEXT:    .long 4294966272 @ 0xfffffc00
; CHECK-NEXT:    .long 0 @ 0x0
; CHECK-NEXT:    .long 4294966272 @ 0xfffffc00
; CHECK-NEXT:    .long 0 @ 0x0
  %and.i = and <2 x i32> %src1, <i32 4294966272, i32 4294966272>
  %vshl_n = lshr <2 x i32> %src2, <i32 22, i32 22>
  %result = or <2 x i32> %and.i, %vshl_n
  ret <2 x i32> %result
}

define <2 x i32> @testRightBad2x32(<2 x i32> %src1, <2 x i32> %src2) {
; CHECK-LABEL: testRightBad2x32:
; CHECK:       @ %bb.0:
; CHECK-NEXT:    vmov.i64 q2, #0xffffffff
; CHECK-NEXT:    vand q1, q1, q2
; CHECK-NEXT:    vmov r0, r1, d3
; CHECK-NEXT:    vmov r2, r3, d2
; CHECK-NEXT:    lsrl r0, r1, #22
; CHECK-NEXT:    lsrl r2, r3, #22
; CHECK-NEXT:    vmov q1[2], q1[0], r2, r0
; CHECK-NEXT:    adr r0, .LCPI19_0
; CHECK-NEXT:    vldrw.u32 q2, [r0]
; CHECK-NEXT:    vmov q1[3], q1[1], r3, r1
; CHECK-NEXT:    vand q0, q0, q2
; CHECK-NEXT:    vorr q0, q0, q1
; CHECK-NEXT:    bx lr
; CHECK-NEXT:    .p2align 4
; CHECK-NEXT:  @ %bb.1:
; CHECK-NEXT:  .LCPI19_0:
; CHECK-NEXT:    .long 4194300 @ 0x3ffffc
; CHECK-NEXT:    .long 0 @ 0x0
; CHECK-NEXT:    .long 4194300 @ 0x3ffffc
; CHECK-NEXT:    .long 0 @ 0x0
  %and.i = and <2 x i32> %src1, <i32 4194300, i32 4194300>
  %vshl_n = lshr <2 x i32> %src2, <i32 22, i32 22>
  %result = or <2 x i32> %and.i, %vshl_n
  ret <2 x i32> %result
}

define <4 x i32> @testLeftGood4x32(<4 x i32> %src1, <4 x i32> %src2) {
; CHECK-LABEL: testLeftGood4x32:
; CHECK:       @ %bb.0:
; CHECK-NEXT:    vsli.32 q0, q1, #22
; CHECK-NEXT:    bx lr
  %and.i = and <4 x i32> %src1, <i32 4194303, i32 4194303, i32 4194303, i32 4194303>
  %vshl_n = shl <4 x i32> %src2, <i32 22, i32 22, i32 22, i32 22>
  %result = or <4 x i32> %and.i, %vshl_n
  ret <4 x i32> %result
}

define <4 x i32> @testLeftBad4x32(<4 x i32> %src1, <4 x i32> %src2) {
; CHECK-LABEL: testLeftBad4x32:
; CHECK:       @ %bb.0:
; CHECK-NEXT:    movw r0, #65532
; CHECK-NEXT:    vshl.i32 q1, q1, #22
; CHECK-NEXT:    movt r0, #63
; CHECK-NEXT:    vdup.32 q2, r0
; CHECK-NEXT:    vand q0, q0, q2
; CHECK-NEXT:    vorr q0, q0, q1
; CHECK-NEXT:    bx lr
  %and.i = and <4 x i32> %src1, <i32 4194300, i32 4194300, i32 4194300, i32 4194300>
  %vshl_n = shl <4 x i32> %src2, <i32 22, i32 22, i32 22, i32 22>
  %result = or <4 x i32> %and.i, %vshl_n
  ret <4 x i32> %result
}

define <4 x i32> @testRightGood4x32(<4 x i32> %src1, <4 x i32> %src2) {
; CHECK-LABEL: testRightGood4x32:
; CHECK:       @ %bb.0:
; CHECK-NEXT:    vsri.32 q0, q1, #22
; CHECK-NEXT:    bx lr
  %and.i = and <4 x i32> %src1, <i32 4294966272, i32 4294966272, i32 4294966272, i32 4294966272>
  %vshl_n = lshr <4 x i32> %src2, <i32 22, i32 22, i32 22, i32 22>
  %result = or <4 x i32> %and.i, %vshl_n
  ret <4 x i32> %result
}

define <4 x i32> @testRightBad4x32(<4 x i32> %src1, <4 x i32> %src2) {
; CHECK-LABEL: testRightBad4x32:
; CHECK:       @ %bb.0:
; CHECK-NEXT:    movw r0, #65532
; CHECK-NEXT:    vshr.u32 q1, q1, #22
; CHECK-NEXT:    movt r0, #63
; CHECK-NEXT:    vdup.32 q2, r0
; CHECK-NEXT:    vand q0, q0, q2
; CHECK-NEXT:    vorr q0, q0, q1
; CHECK-NEXT:    bx lr
  %and.i = and <4 x i32> %src1, <i32 4194300, i32 4194300, i32 4194300, i32 4194300>
  %vshl_n = lshr <4 x i32> %src2, <i32 22, i32 22, i32 22, i32 22>
  %result = or <4 x i32> %and.i, %vshl_n
  ret <4 x i32> %result
}

define <2 x i64> @testLeftGood2x64(<2 x i64> %src1, <2 x i64> %src2) {
; CHECK-LABEL: testLeftGood2x64:
; CHECK:       @ %bb.0:
; CHECK-NEXT:    vmov r0, s6
; CHECK-NEXT:    vmov.i64 q2, #0xffffffffffff
; CHECK-NEXT:    vand q0, q0, q2
; CHECK-NEXT:    lsls r0, r0, #16
; CHECK-NEXT:    vmov s7, r0
; CHECK-NEXT:    vmov r0, s4
; CHECK-NEXT:    vldr s4, .LCPI24_0
; CHECK-NEXT:    vmov.f32 s6, s4
; CHECK-NEXT:    lsls r0, r0, #16
; CHECK-NEXT:    vmov s5, r0
; CHECK-NEXT:    vorr q0, q0, q1
; CHECK-NEXT:    bx lr
; CHECK-NEXT:    .p2align 2
; CHECK-NEXT:  @ %bb.1:
; CHECK-NEXT:  .LCPI24_0:
; CHECK-NEXT:    .long 0x00000000 @ float 0
  %and.i = and <2 x i64> %src1, <i64 281474976710655, i64 281474976710655>
  %vshl_n = shl <2 x i64> %src2, <i64 48, i64 48>
  %result = or <2 x i64> %and.i, %vshl_n
  ret <2 x i64> %result
}

define <2 x i64> @testLeftBad2x64(<2 x i64> %src1, <2 x i64> %src2) {
; CHECK-LABEL: testLeftBad2x64:
; CHECK:       @ %bb.0:
; CHECK-NEXT:    adr r0, .LCPI25_0
; CHECK-NEXT:    vldrw.u32 q2, [r0]
; CHECK-NEXT:    vmov r0, s6
; CHECK-NEXT:    vand q0, q0, q2
; CHECK-NEXT:    lsls r0, r0, #16
; CHECK-NEXT:    vmov s7, r0
; CHECK-NEXT:    vmov r0, s4
; CHECK-NEXT:    vldr s4, .LCPI25_1
; CHECK-NEXT:    vmov.f32 s6, s4
; CHECK-NEXT:    lsls r0, r0, #16
; CHECK-NEXT:    vmov s5, r0
; CHECK-NEXT:    vorr q0, q0, q1
; CHECK-NEXT:    bx lr
; CHECK-NEXT:    .p2align 4
; CHECK-NEXT:  @ %bb.1:
; CHECK-NEXT:  .LCPI25_0:
; CHECK-NEXT:    .long 10 @ 0xa
; CHECK-NEXT:    .long 65536 @ 0x10000
; CHECK-NEXT:    .long 10 @ 0xa
; CHECK-NEXT:    .long 65536 @ 0x10000
; CHECK-NEXT:  .LCPI25_1:
; CHECK-NEXT:    .long 0x00000000 @ float 0
  %and.i = and <2 x i64> %src1, <i64 281474976710666, i64 281474976710666>
  %vshl_n = shl <2 x i64> %src2, <i64 48, i64 48>
  %result = or <2 x i64> %and.i, %vshl_n
  ret <2 x i64> %result
}

define <2 x i64> @testRightGood2x64(<2 x i64> %src1, <2 x i64> %src2) {
; CHECK-LABEL: testRightGood2x64:
; CHECK:       @ %bb.0:
; CHECK-NEXT:    vmov r0, s7
; CHECK-NEXT:    vmov.i64 q2, #0xffffffffffff0000
; CHECK-NEXT:    vand q0, q0, q2
; CHECK-NEXT:    lsrs r0, r0, #16
; CHECK-NEXT:    vmov s6, r0
; CHECK-NEXT:    vmov r0, s5
; CHECK-NEXT:    vldr s5, .LCPI26_0
; CHECK-NEXT:    vmov.f32 s7, s5
; CHECK-NEXT:    lsrs r0, r0, #16
; CHECK-NEXT:    vmov s4, r0
; CHECK-NEXT:    vorr q0, q0, q1
; CHECK-NEXT:    bx lr
; CHECK-NEXT:    .p2align 2
; CHECK-NEXT:  @ %bb.1:
; CHECK-NEXT:  .LCPI26_0:
; CHECK-NEXT:    .long 0x00000000 @ float 0
  %and.i = and <2 x i64> %src1, <i64 18446744073709486080, i64 18446744073709486080>
  %vshl_n = lshr <2 x i64> %src2, <i64 48, i64 48>
  %result = or <2 x i64> %and.i, %vshl_n
  ret <2 x i64> %result
}

define <2 x i64> @testRightBad2x64(<2 x i64> %src1, <2 x i64> %src2) {
; CHECK-LABEL: testRightBad2x64:
; CHECK:       @ %bb.0:
; CHECK-NEXT:    adr r0, .LCPI27_0
; CHECK-NEXT:    vldrw.u32 q2, [r0]
; CHECK-NEXT:    vmov r0, s7
; CHECK-NEXT:    vand q0, q0, q2
; CHECK-NEXT:    lsrs r0, r0, #16
; CHECK-NEXT:    vmov s6, r0
; CHECK-NEXT:    vmov r0, s5
; CHECK-NEXT:    vldr s5, .LCPI27_1
; CHECK-NEXT:    vmov.f32 s7, s5
; CHECK-NEXT:    lsrs r0, r0, #16
; CHECK-NEXT:    vmov s4, r0
; CHECK-NEXT:    vorr q0, q0, q1
; CHECK-NEXT:    bx lr
; CHECK-NEXT:    .p2align 4
; CHECK-NEXT:  @ %bb.1:
; CHECK-NEXT:  .LCPI27_0:
; CHECK-NEXT:    .long 10 @ 0xa
; CHECK-NEXT:    .long 65536 @ 0x10000
; CHECK-NEXT:    .long 10 @ 0xa
; CHECK-NEXT:    .long 65536 @ 0x10000
; CHECK-NEXT:  .LCPI27_1:
; CHECK-NEXT:    .long 0x00000000 @ float 0
  %and.i = and <2 x i64> %src1, <i64 281474976710666, i64 281474976710666>
  %vshl_n = lshr <2 x i64> %src2, <i64 48, i64 48>
  %result = or <2 x i64> %and.i, %vshl_n
  ret <2 x i64> %result
}

define <1 x i128> @testLeftShouldNotCreateSLI1x128(<1 x i128> %src1, <1 x i128> %src2) {
; CHECK-LABEL: testLeftShouldNotCreateSLI1x128:
; CHECK:       @ %bb.0:
; CHECK-NEXT:    ldrd r12, r3, [sp]
; CHECK-NEXT:    and r2, r2, #63
; CHECK-NEXT:    lsll r12, r3, #6
; CHECK-NEXT:    orr.w r2, r2, r12
; CHECK-NEXT:    bx lr
  %and.i = and <1 x i128> %src1, <i128 1180591620717411303423>
  %vshl_n = shl <1 x i128> %src2, <i128 70>
  %result = or <1 x i128> %and.i, %vshl_n
  ret <1 x i128> %result
}

define <8 x i8> @testLeftNotAllConstantBuildVec8x8(<8 x i8> %src1, <8 x i8> %src2) {
; CHECK-LABEL: testLeftNotAllConstantBuildVec8x8:
; CHECK:       @ %bb.0:
; CHECK-NEXT:    adr r0, .LCPI29_0
; CHECK-NEXT:    vshl.i16 q1, q1, #3
; CHECK-NEXT:    vldrw.u32 q2, [r0]
; CHECK-NEXT:    vand q0, q0, q2
; CHECK-NEXT:    vorr q0, q0, q1
; CHECK-NEXT:    bx lr
; CHECK-NEXT:    .p2align 4
; CHECK-NEXT:  @ %bb.1:
; CHECK-NEXT:  .LCPI29_0:
; CHECK-NEXT:    .short 7 @ 0x7
; CHECK-NEXT:    .short 7 @ 0x7
; CHECK-NEXT:    .short 255 @ 0xff
; CHECK-NEXT:    .short 7 @ 0x7
; CHECK-NEXT:    .short 7 @ 0x7
; CHECK-NEXT:    .short 7 @ 0x7
; CHECK-NEXT:    .short 255 @ 0xff
; CHECK-NEXT:    .short 7 @ 0x7
  %and.i = and <8 x i8> %src1, <i8 7, i8 7, i8 255, i8 7, i8 7, i8 7, i8 255, i8 7>
  %vshl_n = shl <8 x i8> %src2, <i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3>
  %result = or <8 x i8> %and.i, %vshl_n
  ret <8 x i8> %result
}
